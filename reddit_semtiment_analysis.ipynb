{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitting-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies\n",
    "#!pip install praw\n",
    "#!pip install psaw\n",
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nominated-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import json\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import traceback\n",
    "\n",
    "# Suppress warning messages\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "refined-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load client_id, secret_id, and user_agent\n",
    "with open('info.json') as f:\n",
    "     info = json.load(f)\n",
    "        \n",
    "info = dict(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laughing-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit and PushshiftAPI instances\n",
    "reddit = praw.Reddit(client_id=info[\"client_id\"], user_agent=info[\"user_agent\"], client_secret=info[\"client_secret\"])\n",
    "api = PushshiftAPI(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e70e2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results of a search in a DataFrame\n",
    "\"\"\"\n",
    "subm_dicts = [{k:getattr(praw_obj, k) for k in vars(praw_obj)} for praw_obj in api.search_submissions(subreddit='stocks', q=\"TWTR\", filter=['url','author', 'title', 'subreddit'], limit=100)]\n",
    "df = pd.DataFrame(subm_dicts)\n",
    "df\n",
    "\"\"\"\n",
    "_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5295a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-07</th>\n",
       "      <td>45.099998</td>\n",
       "      <td>50.090000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>117701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-08</th>\n",
       "      <td>45.930000</td>\n",
       "      <td>46.939999</td>\n",
       "      <td>40.689999</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>27925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-11</th>\n",
       "      <td>40.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>16113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-12</th>\n",
       "      <td>43.660000</td>\n",
       "      <td>43.779999</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>6316700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-13</th>\n",
       "      <td>41.029999</td>\n",
       "      <td>42.869999</td>\n",
       "      <td>40.759998</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>8688300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>47.869999</td>\n",
       "      <td>51.369999</td>\n",
       "      <td>46.860001</td>\n",
       "      <td>49.970001</td>\n",
       "      <td>49.970001</td>\n",
       "      <td>268465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>53.849998</td>\n",
       "      <td>54.570000</td>\n",
       "      <td>50.560001</td>\n",
       "      <td>50.980000</td>\n",
       "      <td>50.980000</td>\n",
       "      <td>217520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>50.040001</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>49.299999</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>159034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07</th>\n",
       "      <td>50.470001</td>\n",
       "      <td>51.639999</td>\n",
       "      <td>46.549999</td>\n",
       "      <td>48.029999</td>\n",
       "      <td>48.029999</td>\n",
       "      <td>120715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-08</th>\n",
       "      <td>47.299999</td>\n",
       "      <td>48.439999</td>\n",
       "      <td>45.832100</td>\n",
       "      <td>46.099998</td>\n",
       "      <td>46.099998</td>\n",
       "      <td>64872741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600\n",
       "2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300\n",
       "2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900\n",
       "2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700\n",
       "2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300\n",
       "...               ...        ...        ...        ...        ...        ...\n",
       "2022-04-04  47.869999  51.369999  46.860001  49.970001  49.970001  268465400\n",
       "2022-04-05  53.849998  54.570000  50.560001  50.980000  50.980000  217520100\n",
       "2022-04-06  50.040001  52.869999  49.299999  50.770000  50.770000  159034700\n",
       "2022-04-07  50.470001  51.639999  46.549999  48.029999  48.029999  120715600\n",
       "2022-04-08  47.299999  48.439999  45.832100  46.099998  46.099998   64872741\n",
       "\n",
       "[2120 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get historical stock data for a ticker\n",
    "twtr = yf.download('TWTR', progress=True)\n",
    "twtr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cee07",
   "metadata": {},
   "source": [
    "## Processing Tickers\n",
    "\n",
    "This initial thought process is not great. I decided that looking for specific words wwould not be a good idea, as it takes much of the context out of the comment. (Something that briefly mentions TSLA, but is actually talking about how great MSFT is would be useless in predicting TSLA stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5ce231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At close, calculate the real and percent change since last close\n",
    "def get_diff(ticker_data):\n",
    "    df = ticker_data.copy()\n",
    "    real = []\n",
    "    percent = []\n",
    "    for index, row in df.reset_index().iterrows():\n",
    "        if(index == 0):\n",
    "            real.append(0)\n",
    "            percent.append(0)\n",
    "        else:\n",
    "            real.append(row[\"Close\"]-df.iloc[index-1][\"Close\"])\n",
    "            percent.append(real[-1]/df.iloc[index-1][\"Close\"])\n",
    "    return real, percent\n",
    "\n",
    "# Get the reddit posts that mention a certain ticker n days before a large change in stock price\n",
    "def get_pre_change_posts(ticker, ticker_gain, days=1, limit=1000, subreddit=\"stocks,stockmarket,stocksandtrading,daytrading,investing,stocks_picks,stockstobuytoday\"):\n",
    "    df = None\n",
    "    for index, row in ticker_gain.iterrows():\n",
    "        start_date = datetime.fromtimestamp(row[\"Date\"].timestamp()) + timedelta(hours=6, days=-days)\n",
    "        end_date = datetime.fromtimestamp(row[\"Date\"].timestamp()) + timedelta(hours=6)\n",
    "        \n",
    "        # TODO: Check whether comments would be better than submissions\n",
    "        \n",
    "        submissions = api.search_comments(after=start_date, before=end_date, q=ticker, subreddit=subreddit, filter=['url','author', 'title', 'subreddit'], limit=limit)\n",
    "        if(df is None):\n",
    "            df = pd.DataFrame([{k:getattr(praw_obj, k) for k in vars(praw_obj)} for praw_obj in submissions])\n",
    "        else:\n",
    "            df = df.append([{k:getattr(praw_obj, k) for k in vars(praw_obj)} for praw_obj in submissions], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def word_counts(df, column=\"body\", min_letters=3):\n",
    "    counts = {}\n",
    "    for i in list(df[column]):\n",
    "        for j in i.split(\" \"):\n",
    "            j = ''.join(k for k in j if k.isalnum())\n",
    "            # Exclude words that are likely tickers\n",
    "            if(j == j.upper() and len(j) > 1 and len(j) <= 5):\n",
    "                pass\n",
    "            elif(len(j) < 3):\n",
    "                pass\n",
    "            elif(j not in counts.keys()):\n",
    "                counts[j.lower()] = 1\n",
    "            else:\n",
    "                counts.update({j.lower():counts.get(j.lower())+1})\n",
    "    return counts\n",
    "\n",
    "def remove_shared_keys(dict_a, dict_b, cutoff=2):\n",
    "    a = dict_a.copy()\n",
    "    b = dict_b.copy()\n",
    "    \n",
    "    rm_a = []\n",
    "    rm_b = []\n",
    "    for i in a:\n",
    "        if(i in b):\n",
    "            if(b.get(i) > 2*a.get(i)):\n",
    "                rm_a.append(i)\n",
    "            elif(b.get(i) < 2*a.get(i)):\n",
    "                rm_b.append(i)\n",
    "            else:\n",
    "                rm_a.append(i)\n",
    "                rm_b.append(i)\n",
    "    for i in rm_a:\n",
    "        a.pop(i)\n",
    "    for i in rm_b:\n",
    "        b.pop(i)\n",
    "    return a, b\n",
    "\n",
    "def remove_infrequent_words(dict_a, min_count=2):\n",
    "    d = dict_a.copy()\n",
    "    \n",
    "    to_remove = []\n",
    "    for i, x in d.items():\n",
    "        if(x < min_count):\n",
    "            to_remove.append(i)\n",
    "            \n",
    "    for i in to_remove:\n",
    "        d.pop(i)\n",
    "        \n",
    "    return d\n",
    "\n",
    "# Generate information for a given ticker\n",
    "def process_ticker(ticker, gain_cutoff=0.05, loss_cutoff=0.05, limit=100, days=1):\n",
    "    try:\n",
    "        ticker_data = yf.download(ticker, progress=False)\n",
    "        ticker_data.reset_index(inplace=True)\n",
    "        real, percent = get_diff(ticker_data)\n",
    "\n",
    "        ticker_data[\"Real_Change\"] = real\n",
    "        ticker_data[\"Percent_Change\"] = percent\n",
    "\n",
    "        ticker_gain = ticker_data[ticker_data[\"Percent_Change\"] > gain_cutoff]\n",
    "        ticker_loss = ticker_data[ticker_data[\"Percent_Change\"] < -loss_cutoff]\n",
    "\n",
    "        pre_gain = get_pre_change_posts(ticker, ticker_gain, days, limit)\n",
    "        pre_loss = get_pre_change_posts(ticker, ticker_loss, days, limit)\n",
    "\n",
    "        gain_wc = dict(sorted(word_counts(pre_gain).items(), key=lambda x: x[1], reverse=True))\n",
    "        loss_wc = dict(sorted(word_counts(pre_loss).items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "        gain_freq = remove_infrequent_words(gain_wc)\n",
    "        loss_freq = remove_infrequent_words(loss_wc)\n",
    "\n",
    "        gain_only, loss_only = remove_shared_keys(gain_freq, loss_freq)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {}, {}\n",
    "    \n",
    "    return gain_only, loss_only\n",
    "\n",
    "#gain_only, loss_only = process_ticker(\"FB\")\n",
    "\n",
    "#gain_only\n",
    "\n",
    "#loss_only\n",
    "\"\"\"\n",
    "all_gain = []\n",
    "all_loss = []\n",
    "for ticker in [\"TWTR\", \"FB\", \"MSFT\", \"ADBE\", \"AAPL\", \"SNAP\", \"AMZN\", \"NCL\", \"DIS\", \"NFLX\"]:\n",
    "    gain_only, loss_only = process_ticker(ticker)\n",
    "    all_gain.append(gain_only)\n",
    "    all_loss.append(loss_only)\n",
    "    print(ticker)\n",
    "\n",
    "def combine_dict_list(list_of_dicts):\n",
    "    single_dict = {}\n",
    "    for d in list_of_dicts:\n",
    "        for i in d:\n",
    "            if(i not in single_dict):\n",
    "                single_dict[i] = d.get(i)\n",
    "            else:\n",
    "                single_dict.update({i:single_dict.get(i)+d.get(i)})\n",
    "    return dict(sorted(single_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "gain, loss = remove_shared_keys(combine_dict_list(all_gain), combine_dict_list(all_loss))\n",
    "\n",
    "gain\n",
    "\n",
    "loss\"\"\"\n",
    "_ = None # This is just to stop automatic output of block commented code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a7a9e",
   "metadata": {},
   "source": [
    "## Better Method (Probably)\n",
    "\n",
    "Instead of looking at posts/comments the day before and predicting whether the next day will close higher, this will be looking at the posts/comments from the previous day's close to the current day's open and predicting whether the close price will be higher than the open price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e3f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(data):\n",
    "    change = []\n",
    "    up = []\n",
    "    for index, row in data.iterrows():\n",
    "        change.append(row[\"Close\"]-row[\"Open\"])\n",
    "        up.append(int(change[-1] > 0))\n",
    "    return change, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9794389",
   "metadata": {},
   "outputs": [],
   "source": [
    "change, up = daily_change(twtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2deb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "twtr[\"Daily_Change\"] = change\n",
    "twtr[\"Positive_Change\"] = up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66dd0005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Positive_Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-07</th>\n",
       "      <td>45.099998</td>\n",
       "      <td>50.090000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>117701600</td>\n",
       "      <td>-0.199997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-08</th>\n",
       "      <td>45.930000</td>\n",
       "      <td>46.939999</td>\n",
       "      <td>40.689999</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>27925300</td>\n",
       "      <td>-4.279999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-11</th>\n",
       "      <td>40.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>16113900</td>\n",
       "      <td>2.400002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-12</th>\n",
       "      <td>43.660000</td>\n",
       "      <td>43.779999</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>6316700</td>\n",
       "      <td>-1.759998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-13</th>\n",
       "      <td>41.029999</td>\n",
       "      <td>42.869999</td>\n",
       "      <td>40.759998</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>8688300</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>47.869999</td>\n",
       "      <td>51.369999</td>\n",
       "      <td>46.860001</td>\n",
       "      <td>49.970001</td>\n",
       "      <td>49.970001</td>\n",
       "      <td>268465400</td>\n",
       "      <td>2.100002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>53.849998</td>\n",
       "      <td>54.570000</td>\n",
       "      <td>50.560001</td>\n",
       "      <td>50.980000</td>\n",
       "      <td>50.980000</td>\n",
       "      <td>217520100</td>\n",
       "      <td>-2.869999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>50.040001</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>49.299999</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>159034700</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07</th>\n",
       "      <td>50.470001</td>\n",
       "      <td>51.639999</td>\n",
       "      <td>46.549999</td>\n",
       "      <td>48.029999</td>\n",
       "      <td>48.029999</td>\n",
       "      <td>120715600</td>\n",
       "      <td>-2.440002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-08</th>\n",
       "      <td>47.299999</td>\n",
       "      <td>48.439999</td>\n",
       "      <td>45.832100</td>\n",
       "      <td>46.099998</td>\n",
       "      <td>46.099998</td>\n",
       "      <td>64872741</td>\n",
       "      <td>-1.200001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   \n",
       "2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   \n",
       "2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   \n",
       "2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   \n",
       "2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-04-04  47.869999  51.369999  46.860001  49.970001  49.970001  268465400   \n",
       "2022-04-05  53.849998  54.570000  50.560001  50.980000  50.980000  217520100   \n",
       "2022-04-06  50.040001  52.869999  49.299999  50.770000  50.770000  159034700   \n",
       "2022-04-07  50.470001  51.639999  46.549999  48.029999  48.029999  120715600   \n",
       "2022-04-08  47.299999  48.439999  45.832100  46.099998  46.099998   64872741   \n",
       "\n",
       "            Daily_Change  Positive_Change  \n",
       "Date                                       \n",
       "2013-11-07     -0.199997                0  \n",
       "2013-11-08     -4.279999                0  \n",
       "2013-11-11      2.400002                1  \n",
       "2013-11-12     -1.759998                0  \n",
       "2013-11-13      1.570000                1  \n",
       "...                  ...              ...  \n",
       "2022-04-04      2.100002                1  \n",
       "2022-04-05     -2.869999                0  \n",
       "2022-04-06      0.730000                1  \n",
       "2022-04-07     -2.440002                0  \n",
       "2022-04-08     -1.200001                0  \n",
       "\n",
       "[2120 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f455dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_open_content(data, ticker, start_hour_diff=0, subreddit=\"stocks,stockmarket,stocksandtrading,daytrading,investing,stocks_picks,stockstobuytoday\", limit=100):\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        end_time = row.name + timedelta(hours=9, minutes=30)\n",
    "        start_time = end_time - timedelta(hours=17, minutes=30)\n",
    "        content = []\n",
    "        for i in api.search_comments(after=start_time, before=end_time, subreddit=subreddit, q=ticker, filter=['url','author', 'title', 'subreddit'], limit=limit):\n",
    "            for j in i.body.split(\".\"):\n",
    "                for k in j.split(\"\\n\"):\n",
    "                    content.append(k)\n",
    "        new_col.append(content)\n",
    "    \n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8130e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zdude\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n",
      "C:\\Users\\zdude\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\Users\\zdude\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    }
   ],
   "source": [
    "twtr_head = twtr.head()\n",
    "twtr[\"Comments\"] = get_pre_open_content(twtr, \"TWTR\", limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13d93656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Positive_Change</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-07</th>\n",
       "      <td>45.099998</td>\n",
       "      <td>50.090000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>117701600</td>\n",
       "      <td>-0.199997</td>\n",
       "      <td>0</td>\n",
       "      <td>[Grab your popcorn and enjoy the TWTR show,  ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-08</th>\n",
       "      <td>45.930000</td>\n",
       "      <td>46.939999</td>\n",
       "      <td>40.689999</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>27925300</td>\n",
       "      <td>-4.279999</td>\n",
       "      <td>0</td>\n",
       "      <td>[How wrong I was,   The IPOX index doesn't inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-11</th>\n",
       "      <td>40.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>39.400002</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>42.900002</td>\n",
       "      <td>16113900</td>\n",
       "      <td>2.400002</td>\n",
       "      <td>1</td>\n",
       "      <td>[Just FYI, implied vol on TWTR options is goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-12</th>\n",
       "      <td>43.660000</td>\n",
       "      <td>43.779999</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>6316700</td>\n",
       "      <td>-1.759998</td>\n",
       "      <td>0</td>\n",
       "      <td>[If you continue to attract new investment cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-13</th>\n",
       "      <td>41.029999</td>\n",
       "      <td>42.869999</td>\n",
       "      <td>40.759998</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>8688300</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>1</td>\n",
       "      <td>[Here are the stock that are on my watch list:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>47.869999</td>\n",
       "      <td>51.369999</td>\n",
       "      <td>46.860001</td>\n",
       "      <td>49.970001</td>\n",
       "      <td>49.970001</td>\n",
       "      <td>268465400</td>\n",
       "      <td>2.100002</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>53.849998</td>\n",
       "      <td>54.570000</td>\n",
       "      <td>50.560001</td>\n",
       "      <td>50.980000</td>\n",
       "      <td>50.980000</td>\n",
       "      <td>217520100</td>\n",
       "      <td>-2.869999</td>\n",
       "      <td>0</td>\n",
       "      <td>[everything is priced in until it’s not,   , ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>50.040001</td>\n",
       "      <td>52.869999</td>\n",
       "      <td>49.299999</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>159034700</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1</td>\n",
       "      <td>[$TWTR bag holders?, TWTR to $1200, TWTR may b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07</th>\n",
       "      <td>50.470001</td>\n",
       "      <td>51.639999</td>\n",
       "      <td>46.549999</td>\n",
       "      <td>48.029999</td>\n",
       "      <td>48.029999</td>\n",
       "      <td>120715600</td>\n",
       "      <td>-2.440002</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-08</th>\n",
       "      <td>47.299999</td>\n",
       "      <td>48.439999</td>\n",
       "      <td>45.832100</td>\n",
       "      <td>46.099998</td>\n",
       "      <td>46.099998</td>\n",
       "      <td>64872741</td>\n",
       "      <td>-1.200001</td>\n",
       "      <td>0</td>\n",
       "      <td>[Musk doesn’t care he wasn’t buying TWTR to ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   \n",
       "2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   \n",
       "2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   \n",
       "2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   \n",
       "2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-04-04  47.869999  51.369999  46.860001  49.970001  49.970001  268465400   \n",
       "2022-04-05  53.849998  54.570000  50.560001  50.980000  50.980000  217520100   \n",
       "2022-04-06  50.040001  52.869999  49.299999  50.770000  50.770000  159034700   \n",
       "2022-04-07  50.470001  51.639999  46.549999  48.029999  48.029999  120715600   \n",
       "2022-04-08  47.299999  48.439999  45.832100  46.099998  46.099998   64872741   \n",
       "\n",
       "            Daily_Change  Positive_Change  \\\n",
       "Date                                        \n",
       "2013-11-07     -0.199997                0   \n",
       "2013-11-08     -4.279999                0   \n",
       "2013-11-11      2.400002                1   \n",
       "2013-11-12     -1.759998                0   \n",
       "2013-11-13      1.570000                1   \n",
       "...                  ...              ...   \n",
       "2022-04-04      2.100002                1   \n",
       "2022-04-05     -2.869999                0   \n",
       "2022-04-06      0.730000                1   \n",
       "2022-04-07     -2.440002                0   \n",
       "2022-04-08     -1.200001                0   \n",
       "\n",
       "                                                     Comments  \n",
       "Date                                                           \n",
       "2013-11-07  [Grab your popcorn and enjoy the TWTR show,  ,...  \n",
       "2013-11-08  [How wrong I was,   The IPOX index doesn't inc...  \n",
       "2013-11-11  [Just FYI, implied vol on TWTR options is goin...  \n",
       "2013-11-12  [If you continue to attract new investment cap...  \n",
       "2013-11-13  [Here are the stock that are on my watch list:...  \n",
       "...                                                       ...  \n",
       "2022-04-04                                                 []  \n",
       "2022-04-05  [everything is priced in until it’s not,   , ,...  \n",
       "2022-04-06  [$TWTR bag holders?, TWTR to $1200, TWTR may b...  \n",
       "2022-04-07                                                 []  \n",
       "2022-04-08  [Musk doesn’t care he wasn’t buying TWTR to ma...  \n",
       "\n",
       "[2120 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twtr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d84754",
   "metadata": {},
   "source": [
    "### Preparing text for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3151eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd196a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(data):\n",
    "    seqs = []\n",
    "    vals = []\n",
    "    for index, row in data.iterrows():\n",
    "        for comment in row[\"Comment_Sequences\"]:\n",
    "            if(comment != []):\n",
    "                seqs.append(comment)\n",
    "                vals.append(row[\"Positive_Change\"])\n",
    "    return seqs, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "468dd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(data, train_proportion = 0.8, max_len=20):\n",
    "    tokenizer = Tokenizer(oov_token = \"<OOV>\")\n",
    "    \n",
    "    # Shuffle the data so that training and testing data are both representative of all timeframes\n",
    "    shuffled = data.sample(frac=1)\n",
    "    \n",
    "    train = shuffled[:int(shuffled.shape[0]*train_proportion)]\n",
    "    test = shuffled[int(shuffled.shape[0]*train_proportion):]\n",
    "    \n",
    "    for comment in train.Comments:\n",
    "        tokenizer.fit_on_texts(comment)\n",
    "        \n",
    "    seqs = []\n",
    "    for comment in train.Comments:\n",
    "        seqs.append(tokenizer.texts_to_sequences(comment))\n",
    "    \n",
    "    train[\"Comment_Sequences\"] = seqs\n",
    "    \n",
    "    X_train, y_train = split_sequences(train)\n",
    "    \n",
    "    X_train = pad_sequences(X_train, padding=\"post\", truncating=\"post\", maxlen=max_len)\n",
    "    \n",
    "    seqs = []\n",
    "    for comment in test.Comments:\n",
    "        seqs.append(tokenizer.texts_to_sequences(comment))\n",
    "    \n",
    "    test[\"Comment_Sequences\"] = seqs\n",
    "    \n",
    "    X_test, y_test = split_sequences(test)\n",
    "    \n",
    "    X_test = pad_sequences(X_test, padding=\"post\", truncating=\"post\", maxlen=max_len)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2fe53a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zdude\\AppData\\Local\\Temp\\ipykernel_8952\\2499109577.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Comment_Sequences\"] = seqs\n",
      "C:\\Users\\zdude\\AppData\\Local\\Temp\\ipykernel_8952\\2499109577.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"Comment_Sequences\"] = seqs\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_text(twtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8d382255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7556, 20)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5766fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7556"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970021d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
